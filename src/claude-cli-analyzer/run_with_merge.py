#!/usr/bin/env python3
"""
ä½¿ç”¨å­—æ®µåˆå¹¶åŠŸèƒ½è¿è¡Œå®Œæ•´åˆ†æ
"""

import sys
import os
import json
from pathlib import Path
from datetime import datetime

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
src_dir = current_dir / "src"
sys.path.insert(0, str(src_dir))

def truncate_value_for_output(value, max_length=100):
    """ä¸ºè¾“å‡ºæˆªæ–­å€¼"""
    if isinstance(value, str) and len(value) > max_length:
        return value[:max_length] + "..."
    elif isinstance(value, (dict, list)):
        str_value = str(value)
        if len(str_value) > max_length:
            return str_value[:max_length] + "..."
        return str_value
    return value

def truncate_examples_list(examples, max_length=100):
    """æˆªæ–­ç¤ºä¾‹å€¼åˆ—è¡¨"""
    return [truncate_value_for_output(example, max_length) for example in examples]

def main():
    print("ğŸš€ å¯åŠ¨Claude CLIå­—æ®µåˆ†æ (åŒ…å«å­—æ®µåˆå¹¶åŠŸèƒ½)")
    print("=" * 60)
    
    try:
        from core.field_extractor import FieldExtractor
        from core.session_scanner import SessionScanner
        
        # 1. æ‰«æä¼šè¯æ–‡ä»¶
        print("\nğŸ“ ç¬¬1æ­¥ï¼šæ‰«æClaude CLIä¼šè¯æ–‡ä»¶...")
        scanner = SessionScanner()
        scan_result = scanner.scan_all_sessions()
        
        print(f"âœ… æ‰«æå®Œæˆï¼")
        print(f"   ğŸ“‚ æ€»æ–‡ä»¶æ•°: {scan_result.total_files}")
        print(f"   ğŸ“ æ€»è®°å½•æ•°: {scan_result.total_records}")
        print(f"   ğŸ’¾ æ€»å¤§å°: {scan_result.total_size_bytes / (1024*1024):.1f} MB")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = current_dir / "outputs"
        output_dir.mkdir(exist_ok=True)
        for subdir in ["sessions", "fields", "reports"]:
            (output_dir / subdir).mkdir(exist_ok=True)
        
        # ä¿å­˜æ‰«æç»“æœ
        scan_result_dict = {
            "total_files": scan_result.total_files,
            "total_records": scan_result.total_records,
            "total_size_bytes": scan_result.total_size_bytes,
            "projects": scan_result.projects,
            "files": [{"path": f.file_path, "size": f.file_size, "records": f.record_count} for f in scan_result.session_files]
        }
        with open(output_dir / "sessions" / "scan_result.json", 'w', encoding='utf-8') as f:
            json.dump(scan_result_dict, f, ensure_ascii=False, indent=2)
        
        # 2. æå–å­—æ®µä¿¡æ¯
        print(f"\nğŸ” ç¬¬2æ­¥ï¼šæå–å­—æ®µä¿¡æ¯...")
        extractor = FieldExtractor()
        
        # å¤„ç†å‰100ä¸ªæ–‡ä»¶ä»¥åŠ å¿«é€Ÿåº¦
        files_to_process = scan_result.session_files[:100]
        processed_count = 0
        
        for i, file_info in enumerate(files_to_process):
            file_path = file_info.file_path
            print(f"[{i+1:3}/{len(files_to_process)}] {Path(file_path).name}")
            
            try:
                count = extractor.process_jsonl_file(file_path, max_records=1000)
                processed_count += count
                
                if processed_count % 5000 == 0:
                    print(f"  å·²ç´¯è®¡å¤„ç† {processed_count} æ¡è®°å½•...")
                    
            except Exception as e:
                print(f"  âš ï¸  å¤„ç†æ–‡ä»¶å‡ºé”™: {e}")
                continue
        
        print(f"âœ… å­—æ®µæå–å®Œæˆï¼Œç´¯è®¡å¤„ç† {processed_count} æ¡è®°å½•")
        
        # 3. ç”Ÿæˆåˆ†æç»“æœï¼ˆè‡ªåŠ¨åŒ…å«å­—æ®µåˆå¹¶ï¼‰
        print(f"\nâš™ï¸  ç¬¬3æ­¥ï¼šç”Ÿæˆåˆ†æç»“æœ (åŒ…å«å­—æ®µåˆå¹¶)")
        
        # æ˜¾ç¤ºåˆå¹¶å‰çš„å­—æ®µæ•°
        print(f"åˆå¹¶å‰å‘ç°å­—æ®µ: {len(extractor.field_registry)} ä¸ª")
        
        # æ˜¾ç¤ºä¸€äº›å…¸å‹çš„é‡å¤å­—æ®µç¤ºä¾‹
        array_fields = [path for path in extractor.field_registry.keys() if '[' in path and ']' in path]
        if array_fields:
            print(f"æ•°ç»„ç´¢å¼•å­—æ®µç¤ºä¾‹:")
            for field in sorted(array_fields)[:5]:
                print(f"   â€¢ {field}")
        
        # ç”Ÿæˆç»“æœï¼ˆä¼šè‡ªåŠ¨è°ƒç”¨å­—æ®µåˆå¹¶ï¼‰
        result = extractor.generate_extraction_result()
        
        print(f"âœ… åˆ†æå®Œæˆï¼")
        print(f"   ğŸ” åˆå¹¶åå­—æ®µæ•°: {result.total_fields_discovered}")
        print(f"   ğŸ“Š å¤„ç†è®°å½•æ€»æ•°: {result.total_records_processed}")
        print(f"   ğŸ·ï¸  æšä¸¾å­—æ®µæ•°: {len(result.enum_fields)}")
        
        # 4. ä¿å­˜ç»“æœ
        print(f"\nğŸ’¾ ç¬¬4æ­¥ï¼šä¿å­˜åˆ†æç»“æœ...")
        
        # ä¿å­˜å­—æ®µæå–ç»“æœ
        result_dict = {
            "ç”Ÿæˆæ—¶é—´": datetime.now().isoformat(),
            "æ€»ç»“": {
                "å¤„ç†æ–‡ä»¶æ•°": len(files_to_process),
                "å¤„ç†è®°å½•æ•°": result.total_records_processed,
                "å‘ç°å­—æ®µæ•°": result.total_fields_discovered,
                "æšä¸¾å­—æ®µæ•°": len(result.enum_fields)
            },
            "æ•°æ®ç±»å‹åˆ†å¸ƒ": result.data_type_distribution,
            "æšä¸¾å­—æ®µ": {path: truncate_examples_list(values) for path, values in result.enum_fields.items()},
            "å­—æ®µè¯¦æƒ…": {}
        }
        
        # è½¬æ¢å­—æ®µä¿¡æ¯
        for path, info in result.field_registry.items():
            result_dict["å­—æ®µè¯¦æƒ…"][path] = {
                "æ•°æ®ç±»å‹": info.data_type,
                "å‡ºç°æ¬¡æ•°": info.occurrence_count,
                "ç©ºå€¼æ¬¡æ•°": info.null_count,
                "ç¤ºä¾‹å€¼": truncate_examples_list(info.value_examples[:3]),
                "æ˜¯å¦æšä¸¾": info.is_enum
            }
        
        # ä¿å­˜ç»“æœ
        with open(output_dir / "fields" / "extraction_result.json", 'w', encoding='utf-8') as f:
            json.dump(result_dict, f, ensure_ascii=False, indent=2)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            "åˆ†ææŠ¥å‘Š": "Claude CLI å­—æ®µåˆ†ææŠ¥å‘Š (å«å­—æ®µåˆå¹¶)",
            "ç”Ÿæˆæ—¶é—´": datetime.now().isoformat(),
            "æ‰«æç»Ÿè®¡": {
                "æ€»æ–‡ä»¶æ•°": scan_result.total_files,
                "å¤„ç†æ–‡ä»¶æ•°": len(files_to_process),
                "æ€»è®°å½•æ•°": scan_result.total_records,
                "å¤„ç†è®°å½•æ•°": result.total_records_processed
            },
            "å­—æ®µç»Ÿè®¡": {
                "å‘ç°å­—æ®µæ€»æ•°": result.total_fields_discovered,
                "æšä¸¾å­—æ®µæ•°": len(result.enum_fields),
                "æ•°æ®ç±»å‹åˆ†å¸ƒ": result.data_type_distribution
            },
            "å­—æ®µåˆå¹¶æ•ˆæœ": {
                "åˆå¹¶å­—æ®µæ•°é‡": len([p for p in result.field_registry.keys() if '[*]' in p]),
                "åˆå¹¶å­—æ®µç¤ºä¾‹": [p for p in result.field_registry.keys() if '[*]' in p][:10]
            }
        }
        
        with open(output_dir / "reports" / "analysis_report.json", 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # 5. æ˜¾ç¤ºç»“æœæ‘˜è¦
        print(f"\nğŸ‰ åˆ†æå®Œæˆï¼ä¸»è¦å‘ç°:")
        print(f"   ğŸ“ å¤„ç†æ–‡ä»¶: {len(files_to_process)} / {scan_result.total_files} ä¸ª")
        print(f"   ğŸ“ å¤„ç†è®°å½•: {result.total_records_processed:,} æ¡")
        print(f"   ğŸ” å‘ç°å­—æ®µ: {result.total_fields_discovered} ä¸ª")
        print(f"   ğŸ·ï¸  æšä¸¾å­—æ®µ: {len(result.enum_fields)} ä¸ª")
        
        # æ˜¾ç¤ºæœ€å¸¸ç”¨å­—æ®µ
        sorted_fields = sorted(result.field_registry.items(), 
                             key=lambda x: x[1].occurrence_count, reverse=True)
        
        print(f"\nğŸ“Š æœ€å¸¸ç”¨çš„10ä¸ªå­—æ®µ:")
        for i, (path, info) in enumerate(sorted_fields[:10], 1):
            print(f"   {i:2d}. {path:<35} {info.data_type:<12} ({info.occurrence_count:,}æ¬¡)")
        
        # æ˜¾ç¤ºå­—æ®µåˆå¹¶æ•ˆæœ
        merged_fields = [path for path in result.field_registry.keys() if '[*]' in path]
        if merged_fields:
            print(f"\nğŸ”„ å­—æ®µåˆå¹¶æ•ˆæœ (å…±{len(merged_fields)}ä¸ªåˆå¹¶å­—æ®µ):")
            for field in merged_fields[:5]:
                info = result.field_registry[field]
                print(f"   â€¢ {field} ({info.occurrence_count:,}æ¬¡)")
        
        print(f"\nğŸ“‚ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
        print(f"   - sessions/scan_result.json")
        print(f"   - fields/extraction_result.json")  
        print(f"   - reports/analysis_report.json")
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)