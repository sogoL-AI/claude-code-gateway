#!/usr/bin/env python3
"""
Claude CLI Field Extractor
é€’å½’æå–å’Œåˆ†æJSONå­—æ®µï¼Œå»ºç«‹å®Œæ•´çš„å­—æ®µæ¸…å•
"""

import json
import ujson
from typing import Dict, List, Set, Any, Union, Optional, Tuple
from dataclasses import dataclass, field
from collections import defaultdict, Counter
import re
from pathlib import Path


@dataclass
class FieldInfo:
    """å­—æ®µä¿¡æ¯"""
    path: str  # å­—æ®µè·¯å¾„ï¼Œå¦‚ "message.content.tool_use.name"
    data_type: str  # æ¨æ–­çš„æ•°æ®ç±»å‹
    value_examples: List[Any] = field(default_factory=list)  # å€¼ç¤ºä¾‹
    occurrence_count: int = 0  # å‡ºç°æ¬¡æ•°
    null_count: int = 0  # nullå€¼æ¬¡æ•°
    unique_values: Set[Any] = field(default_factory=set)  # å”¯ä¸€å€¼é›†åˆ
    is_enum: bool = False  # æ˜¯å¦ä¸ºæšä¸¾ç±»å‹
    enum_values: List[Any] = field(default_factory=list)  # æšä¸¾å€¼åˆ—è¡¨
    value_patterns: List[str] = field(default_factory=list)  # å€¼çš„æ¨¡å¼


@dataclass
class ExtractionResult:
    """æå–ç»“æœ"""
    total_records_processed: int = 0
    total_fields_discovered: int = 0
    field_registry: Dict[str, FieldInfo] = field(default_factory=dict)
    data_type_distribution: Dict[str, int] = field(default_factory=dict)
    enum_fields: Dict[str, List[Any]] = field(default_factory=dict)


class FieldExtractor:
    """å­—æ®µæå–å™¨"""
    
    def __init__(self, max_unique_values: int = 50, max_examples: int = 10, max_value_length: int = 100):
        self.max_unique_values = max_unique_values  # æšä¸¾åˆ¤æ–­é˜ˆå€¼
        self.max_examples = max_examples
        self.max_value_length = max_value_length  # å€¼é•¿åº¦é™åˆ¶
        self.field_registry: Dict[str, FieldInfo] = {}
        
    def truncate_value(self, value: Any) -> Any:
        """æˆªæ–­è¿‡é•¿çš„å€¼"""
        if isinstance(value, str) and len(value) > self.max_value_length:
            return value[:self.max_value_length] + "..."
        elif isinstance(value, (dict, list)):
            # å¯¹å¤æ‚å¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²åæˆªæ–­
            str_value = str(value)
            if len(str_value) > self.max_value_length:
                return str_value[:self.max_value_length] + "..."
            return str_value
        return value
        
    def extract_fields_from_value(self, value: Any, current_path: str = "", max_depth: int = 20) -> None:
        """ä»å€¼ä¸­é€’å½’æå–å­—æ®µï¼Œå¢å¼ºé€’å½’æ·±åº¦"""
        
        if max_depth <= 0:  # é˜²æ­¢æ— é™é€’å½’
            return
            
        if isinstance(value, dict):
            # è®°å½•å¯¹è±¡å­—æ®µæœ¬èº«
            if current_path:
                self._record_field(current_path, value)
                
            for key, val in value.items():
                new_path = f"{current_path}.{key}" if current_path else key
                # æ€»æ˜¯è®°å½•å­—æ®µï¼Œå³ä½¿æ˜¯å¤æ‚ç±»å‹
                self._record_field(new_path, val)
                # é€’å½’å¤„ç†åµŒå¥—å¯¹è±¡ï¼Œå¢åŠ æ·±åº¦æ§åˆ¶
                self.extract_fields_from_value(val, new_path, max_depth - 1)
                
        elif isinstance(value, list):
            # è®°å½•æ•°ç»„å­—æ®µæœ¬èº«
            if current_path:
                self._record_field(current_path, value)
            
            if value:  # éç©ºåˆ—è¡¨
                # åˆ†ææ•°ç»„å…ƒç´ ï¼Œå¢åŠ åˆ†ææ•°é‡
                for i, item in enumerate(value[:10]):  # åˆ†æå‰10ä¸ªå…ƒç´ è€Œä¸æ˜¯5ä¸ª
                    if isinstance(item, (dict, list)):
                        # ä½¿ç”¨é€šç”¨çš„æ•°ç»„å…ƒç´ è·¯å¾„
                        array_item_path = f"{current_path}[{i}]"
                        self.extract_fields_from_value(item, array_item_path, max_depth - 1)
                        
                        # åŒæ—¶ä½¿ç”¨é€šç”¨çš„æ•°ç»„å…ƒç´ æ¨¡å¼
                        if i == 0:  # åªå¯¹ç¬¬ä¸€ä¸ªå…ƒç´ ä½¿ç”¨é€šç”¨æ¨¡å¼
                            generic_array_path = f"{current_path}[]"
                            self.extract_fields_from_value(item, generic_array_path, max_depth - 1)
                    else:
                        # æ•°ç»„ä¸­çš„åŸºæœ¬ç±»å‹å…ƒç´ 
                        array_element_path = f"{current_path}[]"
                        self._record_field(array_element_path, item)
        else:
            # åŸºæœ¬æ•°æ®ç±»å‹å·²åœ¨ä¸Šå±‚è®°å½•
            pass
    
    def _record_field(self, field_path: str, value: Any) -> None:
        """è®°å½•å­—æ®µä¿¡æ¯"""
        
        if field_path not in self.field_registry:
            self.field_registry[field_path] = FieldInfo(
                path=field_path,
                data_type=self._infer_data_type(value),
                unique_values=set()
            )
        
        field_info = self.field_registry[field_path]
        field_info.occurrence_count += 1
        
        # è®°å½•nullå€¼
        if value is None:
            field_info.null_count += 1
            return
        
        # æ›´æ–°æ•°æ®ç±»å‹ï¼ˆå¯èƒ½éœ€è¦æ³›åŒ–ï¼‰
        current_type = self._infer_data_type(value)
        field_info.data_type = self._merge_data_types(field_info.data_type, current_type)
        
        # æ”¶é›†å€¼ç¤ºä¾‹
        if len(field_info.value_examples) < self.max_examples:
            truncated_value = self.truncate_value(value)
            if truncated_value not in field_info.value_examples:  # é¿å…é‡å¤
                field_info.value_examples.append(truncated_value)
        
        # æ”¶é›†å”¯ä¸€å€¼ï¼ˆç”¨äºæšä¸¾åˆ¤æ–­ï¼‰
        if len(field_info.unique_values) < self.max_unique_values:
            # åªå¯¹å­—ç¬¦ä¸²å’Œæ•°å­—ç±»å‹æ”¶é›†å”¯ä¸€å€¼
            if isinstance(value, (str, int, float, bool)):
                field_info.unique_values.add(value)
        
        # åˆ†æå€¼çš„æ¨¡å¼
        if isinstance(value, str):
            pattern = self._extract_string_pattern(value)
            if pattern and pattern not in field_info.value_patterns:
                field_info.value_patterns.append(pattern)
    
    def _infer_data_type(self, value: Any) -> str:
        """æ¨æ–­æ•°æ®ç±»å‹"""
        if value is None:
            return "null"
        elif isinstance(value, bool):
            return "boolean"
        elif isinstance(value, int):
            return "integer"
        elif isinstance(value, float):
            return "number"
        elif isinstance(value, str):
            # è¿›ä¸€æ­¥åˆ†æå­—ç¬¦ä¸²ç±»å‹
            if self._is_uuid(value):
                return "uuid"
            elif self._is_iso_datetime(value):
                return "datetime"
            elif self._is_url(value):
                return "url"
            elif value.startswith(("req_", "toolu_", "msg_")):
                return "id"
            else:
                return "string"
        elif isinstance(value, list):
            if not value:
                return "array[empty]"
            # åˆ†ææ•°ç»„å…ƒç´ ç±»å‹
            element_types = {self._infer_data_type(item) for item in value[:10]}
            if len(element_types) == 1:
                return f"array[{list(element_types)[0]}]"
            else:
                return f"array[mixed]"
        elif isinstance(value, dict):
            return "object"
        else:
            return "unknown"
    
    def _merge_data_types(self, type1: str, type2: str) -> str:
        """åˆå¹¶æ•°æ®ç±»å‹ï¼ˆå¤„ç†ç±»å‹å†²çªï¼‰"""
        if type1 == type2:
            return type1
        
        # å¤„ç†nullç±»å‹
        if type1 == "null":
            return type2
        if type2 == "null":
            return type1
        
        # æ•°å­—ç±»å‹çš„æ³›åŒ–
        if {type1, type2} <= {"integer", "number"}:
            return "number"
        
        # å­—ç¬¦ä¸²å­ç±»å‹çš„æ³›åŒ–
        string_types = {"string", "uuid", "datetime", "url", "id"}
        if {type1, type2} <= string_types:
            return "string"
        
        # æ•°ç»„ç±»å‹çš„å¤„ç†
        if type1.startswith("array") and type2.startswith("array"):
            return "array[mixed]"
        
        # å…¶ä»–æƒ…å†µè¿”å›æ›´é€šç”¨çš„ç±»å‹
        return "mixed"
    
    def _is_uuid(self, value: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºUUIDæ ¼å¼"""
        uuid_pattern = r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$'
        return bool(re.match(uuid_pattern, value, re.IGNORECASE))
    
    def _is_iso_datetime(self, value: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºISOæ—¶é—´æ ¼å¼"""
        iso_pattern = r'^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}(\.\d{3})?Z?$'
        return bool(re.match(iso_pattern, value))
    
    def _is_url(self, value: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºURL"""
        return value.startswith(('http://', 'https://', 'ftp://'))
    
    def _extract_string_pattern(self, value: str) -> str:
        """æå–å­—ç¬¦ä¸²æ¨¡å¼"""
        if self._is_uuid(value):
            return "UUID"
        elif self._is_iso_datetime(value):
            return "ISO_DATETIME"
        elif self._is_url(value):
            return "URL"
        elif value.startswith("req_"):
            return "REQUEST_ID"
        elif value.startswith("toolu_"):
            return "TOOL_USE_ID"
        elif value.startswith("msg_"):
            return "MESSAGE_ID"
        elif re.match(r'^[A-Z_]+$', value):
            return "UPPER_CASE"
        elif re.match(r'^[a-z_]+$', value):
            return "LOWER_CASE"
        elif re.match(r'^\d+$', value):
            return "NUMERIC_STRING"
        else:
            return None
    
    def analyze_enums(self) -> None:
        """åˆ†ææšä¸¾å­—æ®µ"""
        for field_path, field_info in self.field_registry.items():
            # åˆ¤æ–­æ˜¯å¦ä¸ºæšä¸¾ç±»å‹
            unique_count = len(field_info.unique_values)
            total_count = field_info.occurrence_count - field_info.null_count
            
            # æšä¸¾åˆ¤æ–­æ¡ä»¶ï¼š
            # 1. æœ‰è¶³å¤Ÿçš„å‡ºç°æ¬¡æ•°
            # 2. å”¯ä¸€å€¼æ•°é‡ç›¸å¯¹è¾ƒå°‘
            # 3. åŸºæœ¬æ•°æ®ç±»å‹
            if (total_count >= 5 and 
                unique_count <= min(self.max_unique_values, total_count * 0.8) and
                field_info.data_type in ["string", "integer", "boolean"]):
                
                field_info.is_enum = True
                field_info.enum_values = sorted(list(field_info.unique_values))
    
    def process_jsonl_file(self, file_path: str, max_records: int = None) -> int:
        """å¤„ç†JSONLæ–‡ä»¶"""
        processed_count = 0
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line_no, line in enumerate(f, 1):
                    if max_records and processed_count >= max_records:
                        break
                        
                    line = line.strip()
                    if not line:
                        continue
                    
                    try:
                        record = ujson.loads(line)
                        self.extract_fields_from_value(record)
                        processed_count += 1
                        
                        if processed_count % 1000 == 0:
                            print(f"  å·²å¤„ç† {processed_count} æ¡è®°å½•...")
                            
                    except json.JSONDecodeError as e:
                        print(f"  JSONè§£æé”™è¯¯ (è¡Œ {line_no}): {e}")
                        continue
                        
        except Exception as e:
            print(f"æ–‡ä»¶è¯»å–é”™è¯¯ {file_path}: {e}")
            
        return processed_count
    
    def process_json_file(self, file_path: str) -> int:
        """å¤„ç†JSONæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = ujson.load(f)
                self.extract_fields_from_value(data)
                return 1
        except Exception as e:
            print(f"JSONæ–‡ä»¶å¤„ç†é”™è¯¯ {file_path}: {e}")
            return 0
    
    def merge_array_index_fields(self) -> None:
        """åˆå¹¶ç›¸ä¼¼çš„æ•°ç»„ç´¢å¼•å­—æ®µï¼Œå¦‚å°† content[0].title, content[1].title åˆå¹¶ä¸º content[*].title"""
        import re
        from collections import defaultdict
        
        # æŒ‰åŸºç¡€æ¨¡å¼åˆ†ç»„å­—æ®µ
        pattern_groups = defaultdict(list)
        
        for field_path in list(self.field_registry.keys()):
            # å°†æ•°ç»„ç´¢å¼•æ›¿æ¢ä¸ºé€šé…ç¬¦ä»¥è¯†åˆ«æ¨¡å¼
            normalized_path = re.sub(r'\[\d+\]', '[*]', field_path)
            
            # åªå¤„ç†åŒ…å«æ•°ç»„ç´¢å¼•çš„å­—æ®µ
            if '[*]' in normalized_path and normalized_path != field_path:
                pattern_groups[normalized_path].append(field_path)
        
        # åˆå¹¶ç›¸ä¼¼å­—æ®µ
        for normalized_path, similar_fields in pattern_groups.items():
            if len(similar_fields) <= 1:
                continue
                
            # åˆ›å»ºåˆå¹¶åçš„å­—æ®µä¿¡æ¯
            merged_field = FieldInfo(
                path=normalized_path,
                data_type="mixed",
                unique_values=set()
            )
            
            # åˆå¹¶æ‰€æœ‰ç›¸ä¼¼å­—æ®µçš„ä¿¡æ¯
            all_examples = []
            all_patterns = []
            data_types = set()
            
            for field_path in similar_fields:
                field_info = self.field_registry[field_path]
                
                merged_field.occurrence_count += field_info.occurrence_count
                merged_field.null_count += field_info.null_count
                
                # æ”¶é›†æ•°æ®ç±»å‹
                data_types.add(field_info.data_type)
                
                # æ”¶é›†ç¤ºä¾‹å€¼
                all_examples.extend(field_info.value_examples)
                
                # æ”¶é›†æ¨¡å¼
                all_patterns.extend(field_info.value_patterns)
                
                # æ”¶é›†å”¯ä¸€å€¼
                merged_field.unique_values.update(field_info.unique_values)
                
                # åˆ é™¤åŸå§‹å­—æ®µ
                del self.field_registry[field_path]
            
            # è®¾ç½®åˆå¹¶åå­—æ®µçš„æ•°æ®ç±»å‹
            if len(data_types) == 1:
                merged_field.data_type = list(data_types)[0]
            else:
                merged_field.data_type = "mixed"
            
            # å»é‡å¹¶é™åˆ¶ç¤ºä¾‹æ•°é‡ï¼ˆå¤„ç†ä¸å¯å“ˆå¸Œç±»å‹ï¼‰
            unique_examples = []
            seen_examples_str = set()  # ä½¿ç”¨å­—ç¬¦ä¸²è¡¨ç¤ºæ¥å»é‡
            for example in all_examples:
                if len(unique_examples) >= self.max_examples:
                    break
                truncated_example = self.truncate_value(example)
                example_str = str(truncated_example)
                if example_str not in seen_examples_str:
                    seen_examples_str.add(example_str)
                    unique_examples.append(truncated_example)
            merged_field.value_examples = unique_examples
            
            # å»é‡æ¨¡å¼
            merged_field.value_patterns = list(set(all_patterns))
            
            # æ·»åŠ åˆå¹¶åçš„å­—æ®µ
            self.field_registry[normalized_path] = merged_field

    def generate_extraction_result(self) -> ExtractionResult:
        """ç”Ÿæˆæå–ç»“æœ"""
        # åˆ†ææšä¸¾
        self.analyze_enums()
        
        # åˆå¹¶æ•°ç»„ç´¢å¼•å­—æ®µ
        self.merge_array_index_fields()
        
        # ç»Ÿè®¡æ•°æ®ç±»å‹åˆ†å¸ƒ
        type_distribution = Counter()
        enum_fields = {}
        
        for field_path, field_info in self.field_registry.items():
            type_distribution[field_info.data_type] += 1
            
            if field_info.is_enum:
                enum_fields[field_path] = field_info.enum_values
        
        return ExtractionResult(
            total_records_processed=sum(info.occurrence_count for info in self.field_registry.values()),
            total_fields_discovered=len(self.field_registry),
            field_registry=self.field_registry,
            data_type_distribution=dict(type_distribution),
            enum_fields=enum_fields
        )
    
    def print_field_summary(self) -> None:
        """æ‰“å°å­—æ®µæ±‡æ€»ä¿¡æ¯"""
        result = self.generate_extraction_result()
        
        print(f"\nğŸ“Š å­—æ®µæå–æ±‡æ€»:")
        print(f"æ€»å…±å‘ç°å­—æ®µ: {result.total_fields_discovered}")
        print(f"å¤„ç†è®°å½•æ€»æ•°: {result.total_records_processed}")
        print(f"è¯†åˆ«çš„æšä¸¾å­—æ®µ: {len(result.enum_fields)}")
        
        print(f"\nğŸ“ˆ æ•°æ®ç±»å‹åˆ†å¸ƒ:")
        for data_type, count in sorted(result.data_type_distribution.items(), key=lambda x: x[1], reverse=True):
            print(f"  {data_type}: {count}")
        
        print(f"\nğŸ”– æšä¸¾å­—æ®µ:")
        for field_path, enum_values in sorted(result.enum_fields.items()):
            print(f"  {field_path}: {enum_values}")


if __name__ == "__main__":
    # æµ‹è¯•å­—æ®µæå–å™¨
    extractor = FieldExtractor()
    
    # å¯ä»¥æ·»åŠ æµ‹è¯•ä»£ç 
    test_data = {
        "sessionId": "137e4b21-641f-4c6f-b288-ad127c871a24",
        "message": {
            "role": "user",
            "content": [
                {"type": "text", "text": "Hello"},
                {"type": "tool_use", "name": "Read"}
            ]
        },
        "timestamp": "2025-07-31T17:02:24.244Z",
        "isSidechain": False
    }
    
    extractor.extract_fields_from_value(test_data)
    extractor.print_field_summary()