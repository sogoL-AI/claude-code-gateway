#!/usr/bin/env python3
"""
T05: Session-Todoså…³ç³»åˆ†æä»»åŠ¡
æ·±å…¥åˆ†æä¸€å¯¹å¤šå¤æ‚å…³ç³»
"""

import sys
import os
import json
import re
from pathlib import Path
from datetime import datetime
from collections import defaultdict, Counter
from typing import Dict, List, Set, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent
sys.path.insert(0, str(project_root))

from shared.utils import setup_logging


class SessionTodosRelationshipAnalyzer:
    """Session-Todoså…³ç³»åˆ†æå™¨"""
    
    def __init__(self):
        self.session_todos_map: Dict[str, List[dict]] = defaultdict(list)  # session_id -> todos files
        self.agent_session_map: Dict[str, Set[str]] = defaultdict(set)     # agent_id -> session_ids
        self.todos_pattern = re.compile(r'([a-f0-9-]+)-agent-([a-f0-9-]+)\.json$')
        self.session_files: Dict[str, dict] = {}  # session_id -> session file info
        self.todos_files: List[dict] = []
        self.logger = setup_logging("T05_Relationship")
        
    def analyze_relationship_patterns(self, scan_result_file: str) -> Dict:
        """åˆ†æSession-Todoså…³ç³»æ¨¡å¼"""
        
        self.logger.info("å¼€å§‹åˆ†æSession-Todoså¤æ‚å…³ç³»...")
        
        # åŠ è½½æ‰«æç»“æœ
        with open(scan_result_file, 'r', encoding='utf-8') as f:
            scan_data = json.load(f)
        
        file_details = scan_data.get("file_details", [])
        
        # åˆ†ç¦»Sessionå’ŒTodosæ–‡ä»¶
        session_files = [f for f in file_details if f["file_type"] == "jsonl"]
        self.todos_files = [f for f in file_details if f["file_type"] == "json"]
        
        self.logger.info(f"æ–‡ä»¶ç»Ÿè®¡:")
        self.logger.info(f"Sessionæ–‡ä»¶ (.jsonl): {len(session_files)}")
        self.logger.info(f"Todosæ–‡ä»¶ (.json): {len(self.todos_files)}")
        
        # æ„å»ºSessionæ–‡ä»¶ç´¢å¼•
        for session_file in session_files:
            session_id = session_file["session_id"]
            self.session_files[session_id] = session_file
        
        # åˆ†æTodosæ–‡ä»¶å‘½åæ¨¡å¼
        self.logger.info("åˆ†æTodosæ–‡ä»¶å‘½åæ¨¡å¼...")
        
        for todos_file in self.todos_files:
            filename = Path(todos_file["path"]).name
            match = self.todos_pattern.match(filename)
            if match:
                session_id, agent_id = match.groups()
                
                # å»ºç«‹Session-Todosæ˜ å°„
                self.session_todos_map[session_id].append({
                    'file_path': todos_file["path"],
                    'agent_id': agent_id,
                    'modified': todos_file["modified"],
                    'size': todos_file["size"]
                })
                
                # å»ºç«‹Agent-Sessionæ˜ å°„
                self.agent_session_map[agent_id].add(session_id)
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        return self._generate_relationship_analysis()
    
    def _generate_relationship_analysis(self) -> Dict:
        """ç”Ÿæˆå…³ç³»åˆ†ææŠ¥å‘Š"""
        
        self.logger.info("ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        
        analysis = {
            "task_id": "T05",
            "task_name": "Session-Todoså…³ç³»åˆ†æ",
            "generation_time": datetime.now().isoformat(),
            "summary": {
                "total_sessions": len(self.session_files),
                "sessions_with_todos": len(self.session_todos_map),
                "total_todos_files": len(self.todos_files),
                "unique_agents": len(self.agent_session_map)
            },
            "relationship_distribution": self._analyze_relationship_distribution(),
            "agent_reuse_analysis": self._analyze_agent_reuse(),
            "complex_relationships": self._find_complex_relationships(),
            "session_details": []
        }
        
        # è¯¦ç»†Sessionä¿¡æ¯
        for session_id, todos_list in self.session_todos_map.items():
            if session_id in self.session_files:
                session_info = self.session_files[session_id]
                agent_ids = [todo['agent_id'] for todo in todos_list]
                time_span = self._calculate_time_span(todos_list)
                
                session_detail = {
                    "session_id": session_id,
                    "project": session_info["project"],
                    "todos_count": len(todos_list),
                    "unique_agents": len(set(agent_ids)),
                    "has_self_agent": session_id in agent_ids,
                    "session_records": session_info["records"],
                    "time_span_hours": time_span,
                    "agent_pattern": self._analyze_agent_pattern(agent_ids)
                }
                analysis["session_details"].append(session_detail)
        
        # æŒ‰todosæ•°é‡æ’åº
        analysis["session_details"].sort(key=lambda x: x["todos_count"], reverse=True)
        
        return analysis
    
    def _analyze_relationship_distribution(self) -> Dict:
        """åˆ†æå…³ç³»åˆ†å¸ƒ"""
        distribution = {
            "sessions_with_no_todos": len(self.session_files) - len(self.session_todos_map),
            "average_todos_per_session": 0,
            "max_todos_in_single_session": 0,
            "relationship_types": Counter()
        }
        
        if self.session_todos_map:
            todos_counts = [len(todos_list) for todos_list in self.session_todos_map.values()]
            distribution["average_todos_per_session"] = sum(todos_counts) / len(todos_counts)
            distribution["max_todos_in_single_session"] = max(todos_counts)
            
            # åˆ†ç±»å…³ç³»ç±»å‹
            for todos_count in todos_counts:
                if todos_count == 1:
                    distribution["relationship_types"]["1:1"] += 1
                elif todos_count <= 5:
                    distribution["relationship_types"]["1:2-5"] += 1
                elif todos_count <= 10:
                    distribution["relationship_types"]["1:6-10"] += 1
                else:
                    distribution["relationship_types"]["1:10+"] += 1
        
        distribution["relationship_types"] = dict(distribution["relationship_types"])
        return distribution
    
    def _analyze_agent_reuse(self) -> Dict:
        """åˆ†æAgentå¤ç”¨æ¨¡å¼"""
        reuse_analysis = {
            "unique_agents": len(self.agent_session_map),
            "reused_agents": 0,
            "max_sessions_per_agent": 0,
            "agent_distribution": Counter()
        }
        
        for agent_id, session_set in self.agent_session_map.items():
            session_count = len(session_set)
            reuse_analysis["agent_distribution"][session_count] += 1
            
            if session_count > 1:
                reuse_analysis["reused_agents"] += 1
            
            if session_count > reuse_analysis["max_sessions_per_agent"]:
                reuse_analysis["max_sessions_per_agent"] = session_count
        
        reuse_analysis["agent_distribution"] = dict(reuse_analysis["agent_distribution"])
        return reuse_analysis
    
    def _find_complex_relationships(self) -> List[Dict]:
        """è¯†åˆ«å¤æ‚çš„Session-Todoså…³ç³»"""
        complex_sessions = []
        
        for session_id, todos_list in self.session_todos_map.items():
            if len(todos_list) > 1:  # ä¸€å¯¹å¤šå…³ç³»
                if session_id in self.session_files:
                    session_info = self.session_files[session_id]
                    agent_ids = [todo['agent_id'] for todo in todos_list]
                    time_span = self._calculate_time_span(todos_list)
                    
                    complex_sessions.append({
                        'session_id': session_id,
                        'project': session_info["project"],
                        'todos_count': len(todos_list),
                        'unique_agents': len(set(agent_ids)),
                        'has_self_agent': session_id in agent_ids,
                        'session_records': session_info["records"],
                        'time_span_hours': time_span,
                        'agent_pattern': self._analyze_agent_pattern(agent_ids)
                    })
        
        return sorted(complex_sessions, key=lambda x: x['todos_count'], reverse=True)[:10]
    
    def _calculate_time_span(self, todos_list: List[dict]) -> float:
        """è®¡ç®—æ—¶é—´è·¨åº¦"""
        if len(todos_list) < 2:
            return 0.0
        
        try:
            times = [datetime.fromisoformat(todo['modified']) for todo in todos_list]
            time_span = (max(times) - min(times)).total_seconds() / 3600
            return round(time_span, 2)
        except:
            return 0.0
    
    def _analyze_agent_pattern(self, agent_ids: List[str]) -> str:
        """åˆ†æAgentæ¨¡å¼"""
        if len(set(agent_ids)) == 1:
            return "single_agent"
        elif len(agent_ids) == len(set(agent_ids)):
            return "unique_agents"
        else:
            return "mixed_agents"


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("Usage: python relationship_analyzer.py <output_dir>")
        sys.exit(1)
    
    output_dir = Path(sys.argv[1])
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("ğŸ•¸ï¸ T05: Session-Todoså…³ç³»åˆ†æä»»åŠ¡")
    print("=" * 50)
    
    # æŸ¥æ‰¾T06çš„æ‰«æç»“æœ
    scan_result_file = output_dir.parent / "T06_data_scan" / "scan_results.json"
    if not scan_result_file.exists():
        print(f"âŒ ä¾èµ–æ–‡ä»¶ä¸å­˜åœ¨: {scan_result_file}")
        print("   è¯·å…ˆæ‰§è¡Œ T06 æ•°æ®æºæ‰«æä»»åŠ¡")
        sys.exit(1)
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = SessionTodosRelationshipAnalyzer()
    
    # æ‰§è¡Œåˆ†æ
    analysis = analyzer.analyze_relationship_patterns(str(scan_result_file))
    
    # ä¿å­˜åˆ†ææŠ¥å‘Š
    analysis_file = output_dir / "session_todos_relationship_analysis.json"
    with open(analysis_file, 'w', encoding='utf-8') as f:
        json.dump(analysis, f, ensure_ascii=False, indent=2)
    
    # æ‰“å°æ‘˜è¦
    summary = analysis["summary"]
    distribution = analysis["relationship_distribution"]
    agent_reuse = analysis["agent_reuse_analysis"]
    complex_relations = analysis["complex_relationships"]
    
    print(f"\\nğŸ“Š Session-Todoså…³ç³»åˆ†ææ‘˜è¦")
    print(f"ğŸ“ åŸºæœ¬ç»Ÿè®¡:")
    print(f"   æ€»Sessionæ•°: {summary['total_sessions']}")
    print(f"   æœ‰Todosçš„Sessionæ•°: {summary['sessions_with_todos']}")
    print(f"   æ€»Todosæ–‡ä»¶æ•°: {summary['total_todos_files']}")
    print(f"   å”¯ä¸€Agentæ•°: {summary['unique_agents']}")
    
    print(f"\\nğŸ”— Session-Todosåˆ†å¸ƒ:")
    print(f"   å¹³å‡æ¯Sessionçš„Todosæ•°: {distribution['average_todos_per_session']:.1f}")
    print(f"   æœ€å¤šTodosçš„Session: {distribution['max_todos_in_single_session']}ä¸ªæ–‡ä»¶")
    
    print(f"\\nğŸ‘¥ Agentå¤ç”¨åˆ†æ:")
    print(f"   è¢«å¤šä¸ªSessionä½¿ç”¨çš„Agentæ•°: {agent_reuse['reused_agents']}")
    print(f"   å•ä¸ªAgentæœ€å¤šæœåŠ¡Sessionæ•°: {agent_reuse['max_sessions_per_agent']}")
    
    if complex_relations:
        print(f"\\nğŸ¯ å¤æ‚å…³ç³»Session (Top 5):")
        for i, rel in enumerate(complex_relations[:5], 1):
            print(f"   {i}. {rel['session_id']}")
            print(f"      é¡¹ç›®: {rel['project']}")
            print(f"      Todosæ–‡ä»¶: {rel['todos_count']}ä¸ª")
            print(f"      å”¯ä¸€Agent: {rel['unique_agents']}ä¸ª")
            print(f"      Self-Agent: {'æ˜¯' if rel['has_self_agent'] else 'å¦'}")
            print(f"      Sessionè®°å½•: {rel['session_records']}")
            print(f"      æ—¶é—´è·¨åº¦: {rel['time_span_hours']}å°æ—¶")
    
    print(f"\\nğŸ‰ T05ä»»åŠ¡å®Œæˆ! è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {analysis_file}")


if __name__ == "__main__":
    main()