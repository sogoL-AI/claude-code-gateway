#!/usr/bin/env python3
"""
T03: æœ€å°é›†åˆè¦†ç›–åˆ†æä»»åŠ¡
è´ªå¿ƒç®—æ³•å®ç°æœ€ä¼˜Sessioné€‰æ‹©
"""

import sys
import os
import json
import shutil
from pathlib import Path
from datetime import datetime
from collections import defaultdict, Counter
from typing import Dict, Set, List, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent
sys.path.insert(0, str(project_root))

from shared.utils import setup_logging


class MinimalSessionCoverAnalyzer:
    """æœ€å°Sessioné›†åˆè¦†ç›–åˆ†æå™¨"""
    
    def __init__(self):
        self.session_types: Dict[str, Set[str]] = {}  # session_id -> åŒ…å«çš„ç±»å‹é›†åˆ
        self.type_sessions: Dict[str, Set[str]] = defaultdict(set)  # ç±»å‹ -> åŒ…å«æ­¤ç±»å‹çš„sessioné›†åˆ
        self.all_types: Set[str] = set()
        self.session_info: Dict[str, dict] = {}
        self.logger = setup_logging("T03_SetCover")
        
    def analyze_session_types(self, scan_result_file: str, max_sessions: int = None) -> None:
        """åˆ†ææ¯ä¸ªsessionåŒ…å«çš„æ•°æ®ç±»å‹"""
        
        self.logger.info("å¼€å§‹åˆ†ææ¯ä¸ªSessionçš„æ•°æ®ç±»å‹...")
        
        # åŠ è½½æ‰«æç»“æœ
        with open(scan_result_file, 'r', encoding='utf-8') as f:
            scan_data = json.load(f)
        
        # åªåˆ†æJSONLæ–‡ä»¶ï¼ˆé¡¹ç›®ä¼šè¯ï¼‰
        session_files = [f for f in scan_data["file_details"] if f["file_type"] == "jsonl"]
        
        if max_sessions:
            session_files = session_files[:max_sessions]
            self.logger.info(f"é™åˆ¶åˆ†æå‰ {max_sessions} ä¸ªSession")
        
        self.logger.info(f"æ‰¾åˆ° {len(session_files)} ä¸ªSessionæ–‡ä»¶")
        
        processed = 0
        for i, session_file in enumerate(session_files, 1):
            if i % 10 == 0:
                self.logger.info(f"è¿›åº¦: {i}/{len(session_files)} ({processed} ä¸ªå·²å¤„ç†)")
            
            session_id = session_file["session_id"]
            
            # ä¸ºæ¯ä¸ªsessionåˆ›å»ºç‹¬ç«‹çš„ç±»å‹åˆ†æå™¨
            session_type_set = self._analyze_session_file(session_file["path"])
            
            if session_type_set:  # åªè®°å½•æœ‰ç±»å‹çš„session
                self.session_types[session_id] = session_type_set
                self.all_types.update(session_type_set)
                
                # æ›´æ–°åå‘ç´¢å¼•
                for type_sig in session_type_set:
                    self.type_sessions[type_sig].add(session_id)
                
                # è®°å½•sessionåŸºæœ¬ä¿¡æ¯
                self.session_info[session_id] = {
                    'file_path': session_file["path"],
                    'project': session_file["project"],
                    'records': session_file["records"],
                    'size': session_file["size"],
                    'modified': session_file["modified"],
                    'type_count': len(session_type_set)
                }
                processed += 1
        
        self.logger.info(f"åˆ†æå®Œæˆ!")
        self.logger.info(f"æœ‰æ•ˆSession: {len(self.session_types)}")
        self.logger.info(f"å‘ç°ç±»å‹æ€»æ•°: {len(self.all_types)}")
        self.logger.info(f"å¹³å‡æ¯Sessionç±»å‹æ•°: {sum(len(types) for types in self.session_types.values()) / len(self.session_types):.1f}")
    
    def _analyze_session_file(self, file_path: str) -> Set[str]:
        """åˆ†æå•ä¸ªsessionæ–‡ä»¶çš„æ•°æ®ç±»å‹"""
        from tasks.T02_message_structure_type.type_analyzer import ObjectTypeAnalyzer
        
        analyzer = ObjectTypeAnalyzer()
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    
                    try:
                        record = json.loads(line)
                        analyzer.analyze_record(record)
                    except json.JSONDecodeError:
                        continue
        except Exception as e:
            self.logger.warning(f"åˆ†ææ–‡ä»¶é”™è¯¯ {file_path}: {e}")
            return set()
        
        return set(analyzer.object_types.keys())
    
    def greedy_set_cover(self) -> List[str]:
        """è´ªå¿ƒç®—æ³•æ±‚è§£æœ€å°é›†åˆè¦†ç›–"""
        
        self.logger.info(f"å¼€å§‹è´ªå¿ƒç®—æ³•æ±‚è§£æœ€å°é›†åˆè¦†ç›–...")
        self.logger.info(f"ç›®æ ‡: ç”¨æœ€å°‘Sessionè¦†ç›– {len(self.all_types)} ç§æ•°æ®ç±»å‹")
        
        uncovered_types = self.all_types.copy()
        selected_sessions = []
        
        iteration = 0
        while uncovered_types:
            iteration += 1
            
            # æ‰¾åˆ°èƒ½è¦†ç›–æœ€å¤šæœªè¦†ç›–ç±»å‹çš„session
            best_session = None
            best_coverage = 0
            best_new_types = set()
            
            for session_id, session_types in self.session_types.items():
                if session_id in selected_sessions:
                    continue
                
                # è®¡ç®—è¿™ä¸ªsessionèƒ½æ–°è¦†ç›–å¤šå°‘ç±»å‹
                new_types = session_types & uncovered_types
                coverage = len(new_types)
                
                if coverage > best_coverage:
                    best_coverage = coverage
                    best_session = session_id
                    best_new_types = new_types
            
            if best_session is None:
                break
            
            # é€‰æ‹©æœ€ä½³session
            selected_sessions.append(best_session)
            uncovered_types -= best_new_types
            
            coverage_percent = (len(self.all_types) - len(uncovered_types)) / len(self.all_types) * 100
            
            self.logger.info(f"ç¬¬{iteration}è½®: é€‰æ‹© {best_session}")
            self.logger.info(f"  æ–°è¦†ç›–ç±»å‹: {best_coverage}")
            self.logger.info(f"  ç´¯è®¡è¦†ç›–: {len(self.all_types) - len(uncovered_types)}/{len(self.all_types)} ({coverage_percent:.1f}%)")
            self.logger.info(f"  å‰©ä½™ç±»å‹: {len(uncovered_types)}")
        
        if uncovered_types:
            self.logger.warning(f"ä»æœ‰ {len(uncovered_types)} ä¸ªç±»å‹æœªè¦†ç›–")
        
        self.logger.info(f"ç®—æ³•å®Œæˆ!")
        self.logger.info(f"é€‰æ‹©Sessionæ•°: {len(selected_sessions)}")
        self.logger.info(f"è¦†ç›–ç‡: {(len(self.all_types) - len(uncovered_types)) / len(self.all_types) * 100:.2f}%")
        
        return selected_sessions
    
    def analyze_coverage_efficiency(self, selected_sessions: List[str]) -> Dict:
        """åˆ†æè¦†ç›–æ•ˆç‡"""
        
        analysis = {
            "task_id": "T03",
            "task_name": "æœ€å°é›†åˆè¦†ç›–åˆ†æ",
            "execution_time": datetime.now().isoformat(),
            "total_sessions_available": len(self.session_types),
            "selected_sessions": len(selected_sessions),
            "reduction_ratio": len(selected_sessions) / len(self.session_types),
            "total_types": len(self.all_types),
            "covered_types": 0,
            "coverage_details": [],
            "type_frequency_analysis": {},
            "session_details": []
        }
        
        covered_types = set()
        
        for i, session_id in enumerate(selected_sessions, 1):
            session_types = self.session_types[session_id]
            new_types = session_types - covered_types
            covered_types.update(session_types)
            
            session_detail = {
                "rank": i,
                "session_id": session_id,
                "project": self.session_info[session_id]['project'],
                "total_types_in_session": len(session_types),
                "new_types_contributed": len(new_types),
                "cumulative_coverage": len(covered_types),
                "coverage_percentage": len(covered_types) / len(self.all_types) * 100,
                "records": self.session_info[session_id]['records'],
                "size_mb": self.session_info[session_id]['size'] / 1024 / 1024
            }
            
            analysis["session_details"].append(session_detail)
        
        analysis["covered_types"] = len(covered_types)
        analysis["coverage_percentage"] = len(covered_types) / len(self.all_types) * 100
        
        # åˆ†æç±»å‹é¢‘ç‡
        type_frequencies = Counter()
        for session_types in self.session_types.values():
            for type_sig in session_types:
                type_frequencies[type_sig] += 1
        
        analysis["type_frequency_analysis"] = {
            "rare_types_1_session": sum(1 for count in type_frequencies.values() if count == 1),
            "common_types_5plus_sessions": sum(1 for count in type_frequencies.values() if count >= 5),
            "very_common_types_10plus_sessions": sum(1 for count in type_frequencies.values() if count >= 10),
        }
        
        return analysis
    
    def extract_selected_sessions(self, selected_sessions: List[str], output_dir: Path) -> None:
        """æå–é€‰ä¸­çš„sessionåˆ°æŒ‡å®šç›®å½•"""
        
        self.logger.info(f"æå–é€‰ä¸­çš„Sessionåˆ°ç›®å½•: {output_dir}")
        
        session_dir = output_dir / "selected_sessions"
        session_dir.mkdir(parents=True, exist_ok=True)
        
        # æå–æ¯ä¸ªé€‰ä¸­çš„session
        for i, session_id in enumerate(selected_sessions, 1):
            self.logger.info(f"[{i}/{len(selected_sessions)}] æå–Session: {session_id}")
            
            session_info = self.session_info[session_id]
            source_path = Path(session_info['file_path'])
            
            # åˆ›å»ºç›®æ ‡æ–‡ä»¶å
            target_name = f"session_{i:02d}_{session_id}.jsonl"
            target_path = session_dir / target_name
            
            # å¤åˆ¶æ–‡ä»¶
            shutil.copy2(source_path, target_path)
            
            self.logger.info(f"  é¡¹ç›®: {session_info['project']}")
            self.logger.info(f"  ç±»å‹æ•°: {session_info['type_count']}")
            self.logger.info(f"  è®°å½•æ•°: {session_info['records']}")
            self.logger.info(f"  â†’ å·²æå–åˆ°: {target_name}")
        
        self.logger.info(f"æ‰€æœ‰Sessionå·²æå–åˆ°: {session_dir}")


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("Usage: python set_cover_analyzer.py <output_dir> [max_sessions]")
        sys.exit(1)
    
    output_dir = Path(sys.argv[1])
    output_dir.mkdir(parents=True, exist_ok=True)
    
    max_sessions = None
    if len(sys.argv) > 2 and sys.argv[2].isdigit():
        max_sessions = int(sys.argv[2])
    
    print("ğŸ§® T03: æœ€å°é›†åˆè¦†ç›–åˆ†æä»»åŠ¡")
    print("=" * 50)
    
    if max_sessions:
        print(f"é™åˆ¶åˆ†æSessionæ•°: {max_sessions}")
    
    # æŸ¥æ‰¾T06çš„æ‰«æç»“æœ
    scan_result_file = output_dir.parent / "T06_data_scan" / "scan_results.json"
    if not scan_result_file.exists():
        print(f"âŒ ä¾èµ–æ–‡ä»¶ä¸å­˜åœ¨: {scan_result_file}")
        print("   è¯·å…ˆæ‰§è¡Œ T06 æ•°æ®æºæ‰«æä»»åŠ¡")
        sys.exit(1)
    
    # åˆ›å»ºè¦†ç›–ç®—æ³•å®ä¾‹
    cover_algo = MinimalSessionCoverAnalyzer()
    
    # åˆ†ææ¯ä¸ªsessionçš„ç±»å‹
    cover_algo.analyze_session_types(str(scan_result_file), max_sessions)
    
    # æ‰§è¡Œè´ªå¿ƒç®—æ³•
    selected_sessions = cover_algo.greedy_set_cover()
    
    # åˆ†æè¦†ç›–æ•ˆç‡
    analysis = cover_algo.analyze_coverage_efficiency(selected_sessions)
    
    # ä¿å­˜åˆ†æç»“æœ
    analysis_file = output_dir / "coverage_analysis.json"
    with open(analysis_file, 'w', encoding='utf-8') as f:
        json.dump(analysis, f, ensure_ascii=False, indent=2)
    
    # æ‰“å°æ‘˜è¦
    print(f"\\nğŸ“Š è¦†ç›–æ•ˆç‡åˆ†æ:")
    print(f"   åŸå§‹Sessionæ•°: {analysis['total_sessions_available']}")
    print(f"   é€‰æ‹©Sessionæ•°: {analysis['selected_sessions']}")
    print(f"   å‹ç¼©æ¯”: {analysis['reduction_ratio']:.1%} (å‡å°‘ {(1-analysis['reduction_ratio'])*100:.1f}%)")
    print(f"   ç±»å‹è¦†ç›–ç‡: {analysis['coverage_percentage']:.2f}%")
    print(f"   ç¨€æœ‰ç±»å‹(ä»…1ä¸ªSession): {analysis['type_frequency_analysis']['rare_types_1_session']}")
    print(f"   å¸¸è§ç±»å‹(5+Session): {analysis['type_frequency_analysis']['common_types_5plus_sessions']}")
    
    print(f"\\nğŸ“‹ å‰5ä¸ªå…³é”®Session:")
    for session in analysis["session_details"][:5]:
        print(f"   {session['rank']}. {session['session_id']}")
        print(f"      é¡¹ç›®: {session['project']}")
        print(f"      è´¡çŒ®æ–°ç±»å‹: {session['new_types_contributed']}")
        print(f"      ç´¯è®¡è¦†ç›–: {session['coverage_percentage']:.1f}%")
    
    # æå–é€‰ä¸­çš„session
    cover_algo.extract_selected_sessions(selected_sessions, output_dir)
    
    print(f"\\nğŸ‰ T03ä»»åŠ¡å®Œæˆ! åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {analysis_file}")


if __name__ == "__main__":
    main()