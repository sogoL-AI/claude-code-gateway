#!/usr/bin/env python3
"""
T04: Session IDç»§æ‰¿æœºåˆ¶åˆ†æä»»åŠ¡
åˆ†æclaude -cå‘½ä»¤çš„ç»§æ‰¿è¡Œä¸º
"""

import sys
import os
import json
import re
from pathlib import Path
from datetime import datetime, timedelta
from collections import defaultdict, Counter
from typing import Dict, List, Set, Tuple, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent
sys.path.insert(0, str(project_root))

from shared.utils import setup_logging


class SessionInheritanceAnalyzer:
    """Session IDç»§æ‰¿æœºåˆ¶åˆ†æå™¨"""
    
    def __init__(self):
        self.session_files: Dict[str, dict] = {}  # session_id -> file info
        self.session_records: Dict[str, List[dict]] = defaultdict(list)  # session_id -> records
        self.session_temporal_data: List[dict] = []  # æ—¶é—´åºåˆ—æ•°æ®
        self.logger = setup_logging("T04_Inheritance")
        
    def analyze_session_inheritance(self, scan_result_file: str) -> Dict:
        """åˆ†æSession IDç»§æ‰¿æœºåˆ¶"""
        
        self.logger.info("å¼€å§‹åˆ†æSession IDç»§æ‰¿å’Œæ›´æ–°æœºåˆ¶...")
        
        # åŠ è½½æ‰«æç»“æœ
        with open(scan_result_file, 'r', encoding='utf-8') as f:
            scan_data = json.load(f)
        
        # æ”¶é›†sessionæ–‡ä»¶ä¿¡æ¯
        session_files = [f for f in scan_data["file_details"] if f["file_type"] == "jsonl"]
        
        self.logger.info(f"å‘ç° {len(session_files)} ä¸ªSessionæ–‡ä»¶")
        
        # åˆ†ææ¯ä¸ªsessionæ–‡ä»¶
        for session_file in session_files:
            session_id = session_file["session_id"]
            self.session_files[session_id] = {
                'path': session_file["path"],
                'size': session_file["size"],
                'records': session_file["records"],
                'modified': datetime.fromisoformat(session_file["modified"]),
                'project': session_file["project"]
            }
            
            # è¯»å–sessionè®°å½•æ¥åˆ†ææ—¶é—´æ¨¡å¼
            self._load_session_records(session_file)
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        return self._generate_inheritance_analysis()
    
    def _load_session_records(self, session_file) -> None:
        """åŠ è½½sessionè®°å½•"""
        try:
            with open(session_file["path"], 'r', encoding='utf-8') as f:
                records = []
                for line_num, line in enumerate(f, 1):
                    if line.strip():
                        try:
                            record = json.loads(line)
                            # æ·»åŠ è®°å½•æ—¶é—´ä¿¡æ¯
                            if 'timestamp' in record:
                                # ç»Ÿä¸€å¤„ç†ä¸ºnaive datetime
                                timestamp_str = record['timestamp'].replace('Z', '').replace('+00:00', '')
                                if '.' not in timestamp_str:
                                    timestamp_str += '.000000'
                                record['_parsed_timestamp'] = datetime.fromisoformat(timestamp_str)
                            records.append(record)
                        except (json.JSONDecodeError, ValueError):
                            continue
                
                self.session_records[session_file["session_id"]] = records
                
                # åˆ†ææ–‡ä»¶åˆ›å»ºæ—¶é—´ vs é¦–æ¡è®°å½•æ—¶é—´
                if records:
                    first_record_time = records[0].get('_parsed_timestamp')
                    last_record_time = records[-1].get('_parsed_timestamp') if len(records) > 1 else first_record_time
                    
                    self.session_temporal_data.append({
                        'session_id': session_file["session_id"],
                        'project': session_file["project"],
                        'file_modified': datetime.fromisoformat(session_file["modified"]),
                        'first_record_time': first_record_time,
                        'last_record_time': last_record_time,
                        'record_count': len(records),
                        'file_size': session_file["size"],
                        'time_span_hours': (last_record_time - first_record_time).total_seconds() / 3600 if first_record_time and last_record_time else 0
                    })
                    
        except Exception as e:
            self.logger.warning(f"æ— æ³•è¯»å–sessionæ–‡ä»¶ {session_file['path']}: {e}")
    
    def _generate_inheritance_analysis(self) -> Dict:
        """ç”Ÿæˆç»§æ‰¿æœºåˆ¶åˆ†ææŠ¥å‘Š"""
        
        self.logger.info(f"ç”ŸæˆSession IDç»§æ‰¿åˆ†ææŠ¥å‘Š...")
        
        analysis = {
            "task_id": "T04",
            "task_name": "Session IDç»§æ‰¿æœºåˆ¶åˆ†æ",
            "generation_time": datetime.now().isoformat(),
            "summary": {
                "total_sessions": len(self.session_files),
                "sessions_with_records": len([s for s in self.session_temporal_data if s['record_count'] > 0]),
                "total_records": sum(len(records) for records in self.session_records.values())
            },
            "file_creation_patterns": self._analyze_file_creation_patterns(),
            "session_timing_analysis": self._analyze_session_timing(),
            "inheritance_indicators": self._find_inheritance_indicators(),
            "storage_behavior_analysis": self._analyze_storage_behavior(),
            "potential_continuations": self._find_potential_continuations(),
            "session_details": []
        }
        
        # è¯¦ç»†sessionä¿¡æ¯
        for session_data in self.session_temporal_data:
            session_id = session_data['session_id']
            session_detail = {
                **session_data,
                "file_vs_record_timing": self._analyze_file_record_timing(session_data),
                "session_pattern": self._classify_session_pattern(session_data)
            }
            # è½¬æ¢datetimeä¸ºå­—ç¬¦ä¸²
            session_detail['file_modified'] = session_detail['file_modified'].isoformat()
            if session_detail['first_record_time']:
                session_detail['first_record_time'] = session_detail['first_record_time'].isoformat()
            if session_detail['last_record_time']:
                session_detail['last_record_time'] = session_detail['last_record_time'].isoformat()
            
            analysis["session_details"].append(session_detail)
        
        # æŒ‰è®°å½•æ•°æ’åº
        analysis["session_details"].sort(key=lambda x: x["record_count"], reverse=True)
        
        return analysis
    
    def _analyze_file_creation_patterns(self) -> Dict:
        """åˆ†ææ–‡ä»¶åˆ›å»ºæ¨¡å¼"""
        
        patterns = {
            "immediate_creation": 0,  # æ–‡ä»¶åˆ›å»ºæ—¶é—´ â‰ˆ é¦–æ¡è®°å½•æ—¶é—´
            "delayed_creation": 0,    # æ–‡ä»¶åˆ›å»ºæ—¶é—´ > é¦–æ¡è®°å½•æ—¶é—´
            "pre_creation": 0,        # æ–‡ä»¶åˆ›å»ºæ—¶é—´ < é¦–æ¡è®°å½•æ—¶é—´
            "timing_differences": []
        }
        
        for session_data in self.session_temporal_data:
            if session_data['first_record_time']:
                file_time = session_data['file_modified']
                record_time = session_data['first_record_time']
                
                # è®¡ç®—æ—¶é—´å·®ï¼ˆç§’ï¼‰
                time_diff = (file_time - record_time).total_seconds()
                patterns["timing_differences"].append({
                    "session_id": session_data['session_id'],
                    "time_diff_seconds": time_diff,
                    "pattern": "immediate" if abs(time_diff) < 60 else ("delayed" if time_diff > 0 else "pre")
                })
                
                if abs(time_diff) < 60:  # 1åˆ†é’Ÿå†…è®¤ä¸ºæ˜¯å³æ—¶åˆ›å»º
                    patterns["immediate_creation"] += 1
                elif time_diff > 0:
                    patterns["delayed_creation"] += 1
                else:
                    patterns["pre_creation"] += 1
        
        return patterns
    
    def _analyze_session_timing(self) -> Dict:
        """åˆ†æsessionæ—¶é—´æ¨¡å¼"""
        
        # æŒ‰æ—¶é—´æ’åº
        sorted_sessions = sorted(self.session_temporal_data, 
                                key=lambda x: x['first_record_time'] or datetime.min)
        
        timing_analysis = {
            "sessions_by_hour": defaultdict(int),
            "session_duration_distribution": Counter(),
            "rapid_succession_sessions": [],  # å¿«é€Ÿè¿ç»­åˆ›å»ºçš„session
        }
        
        # åˆ†æåˆ›å»ºæ—¶é—´åˆ†å¸ƒ
        for session_data in sorted_sessions:
            if session_data['first_record_time']:
                hour = session_data['first_record_time'].hour
                timing_analysis["sessions_by_hour"][hour] += 1
                
                # æŒç»­æ—¶é—´åˆ†ç±»
                duration_hours = session_data['time_span_hours']
                if duration_hours < 0.1:
                    timing_analysis["session_duration_distribution"]["<6min"] += 1
                elif duration_hours < 1:
                    timing_analysis["session_duration_distribution"]["<1hour"] += 1
                elif duration_hours < 6:
                    timing_analysis["session_duration_distribution"]["1-6hours"] += 1
                else:
                    timing_analysis["session_duration_distribution"][">6hours"] += 1
        
        # å¯»æ‰¾å¿«é€Ÿè¿ç»­åˆ›å»ºçš„sessionï¼ˆå¯èƒ½çš„-cè¡Œä¸ºï¼‰
        for i in range(1, len(sorted_sessions)):
            current = sorted_sessions[i]
            previous = sorted_sessions[i-1]
            
            if (current['first_record_time'] and previous['first_record_time'] and
                (current['first_record_time'] - previous['first_record_time']).total_seconds() < 300):  # 5åˆ†é’Ÿå†…
                
                timing_analysis["rapid_succession_sessions"].append({
                    "previous_session": previous['session_id'],
                    "current_session": current['session_id'],
                    "time_gap_seconds": (current['first_record_time'] - previous['first_record_time']).total_seconds(),
                    "same_project": current['project'] == previous['project']
                })
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        timing_analysis["sessions_by_hour"] = dict(timing_analysis["sessions_by_hour"])
        timing_analysis["session_duration_distribution"] = dict(timing_analysis["session_duration_distribution"])
        
        return timing_analysis
    
    def _find_inheritance_indicators(self) -> List[Dict]:
        """å¯»æ‰¾å¯èƒ½çš„ç»§æ‰¿æŒ‡ç¤ºå™¨"""
        # ç®€åŒ–å®ç°
        return []
    
    def _analyze_storage_behavior(self) -> Dict:
        """åˆ†æå­˜å‚¨è¡Œä¸º"""
        behavior = {
            "new_file_creation": 0,     # æ˜ç¡®æ–°å»ºæ–‡ä»¶
            "file_continuation": 0,     # å¯èƒ½çš„æ–‡ä»¶ç»§ç»­å†™å…¥
        }
        
        for session_data in self.session_temporal_data:
            file_record_analysis = self._analyze_file_record_timing(session_data)
            
            if file_record_analysis["likely_new_file"]:
                behavior["new_file_creation"] += 1
            else:
                behavior["file_continuation"] += 1
        
        return behavior
    
    def _find_potential_continuations(self) -> List[Dict]:
        """å¯»æ‰¾å¯èƒ½çš„sessionå»¶ç»­"""
        continuations = []
        
        # æŒ‰é¡¹ç›®åˆ†ç»„åˆ†æ
        by_project = defaultdict(list)
        for session_data in self.session_temporal_data:
            by_project[session_data['project']].append(session_data)
        
        for project, sessions in by_project.items():
            # æŒ‰æ—¶é—´æ’åº
            sessions.sort(key=lambda x: x['first_record_time'] or datetime.min)
            
            for i in range(1, len(sessions)):
                current = sessions[i]
                previous = sessions[i-1]
                
                # æ£€æŸ¥æ˜¯å¦å¯èƒ½æ˜¯å»¶ç»­session
                if (current['first_record_time'] and previous['last_record_time'] and
                    (current['first_record_time'] - previous['last_record_time']).total_seconds() < 3600):  # 1å°æ—¶å†…
                    
                    continuations.append({
                        "project": project,
                        "previous_session": previous['session_id'],
                        "current_session": current['session_id'],
                        "gap_minutes": (current['first_record_time'] - previous['last_record_time']).total_seconds() / 60,
                        "context_preservation_score": self._calculate_context_score(previous, current)
                    })
        
        return continuations[:10]  # è¿”å›å‰10ä¸ª
    
    def _analyze_file_record_timing(self, session_data: Dict) -> Dict:
        """åˆ†ææ–‡ä»¶å’Œè®°å½•çš„æ—¶é—´å…³ç³»"""
        
        if not session_data['first_record_time']:
            return {"likely_new_file": True, "confidence": 0.5, "reason": "no_record_timestamp"}
        
        time_diff = (session_data['file_modified'] - session_data['first_record_time']).total_seconds()
        
        if abs(time_diff) < 10:  # 10ç§’å†…
            return {"likely_new_file": True, "confidence": 0.9, "reason": "immediate_creation"}
        elif time_diff > 0:  # æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ™šäºé¦–æ¡è®°å½•
            return {"likely_new_file": False, "confidence": 0.7, "reason": "delayed_file_update"}
        else:  # æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ—©äºé¦–æ¡è®°å½•
            return {"likely_new_file": False, "confidence": 0.8, "reason": "pre_existing_file"}
    
    def _classify_session_pattern(self, session_data: Dict) -> str:
        """åˆ†ç±»sessionæ¨¡å¼"""
        
        records = session_data['record_count']
        duration = session_data['time_span_hours']
        
        if records == 0:
            return "empty"
        elif records == 1:
            return "single_interaction"
        elif duration < 0.1:
            return "burst_interaction"
        elif duration < 1:
            return "short_session"
        elif duration < 6:
            return "medium_session"
        else:
            return "long_session"
    
    def _calculate_context_score(self, previous: Dict, current: Dict) -> float:
        """è®¡ç®—ä¸Šä¸‹æ–‡ä¿æŒå¾—åˆ†"""
        score = 0.0
        
        # åŒä¸€é¡¹ç›® +0.3
        if previous['project'] == current['project']:
            score += 0.3
        
        # æ—¶é—´é—´éš”è¶ŠçŸ­å¾—åˆ†è¶Šé«˜ +0.4
        if previous['last_record_time'] and current['first_record_time']:
            gap_hours = (current['first_record_time'] - previous['last_record_time']).total_seconds() / 3600
            if gap_hours < 0.1:  # 6åˆ†é’Ÿå†…
                score += 0.4
            elif gap_hours < 1:  # 1å°æ—¶å†…
                score += 0.3
            elif gap_hours < 6:  # 6å°æ—¶å†…
                score += 0.2
        
        # ç›¸ä¼¼çš„æŒç»­æ—¶é—´æ¨¡å¼ +0.3
        if abs(previous['time_span_hours'] - current['time_span_hours']) < 1:
            score += 0.3
        
        return min(score, 1.0)


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("Usage: python inheritance_analyzer.py <output_dir>")
        sys.exit(1)
    
    output_dir = Path(sys.argv[1])
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("ğŸ†” T04: Session IDç»§æ‰¿æœºåˆ¶åˆ†æä»»åŠ¡")
    print("=" * 50)
    
    # æŸ¥æ‰¾T06çš„æ‰«æç»“æœ
    scan_result_file = output_dir.parent / "T06_data_scan" / "scan_results.json"
    if not scan_result_file.exists():
        print(f"âŒ ä¾èµ–æ–‡ä»¶ä¸å­˜åœ¨: {scan_result_file}")
        print("   è¯·å…ˆæ‰§è¡Œ T06 æ•°æ®æºæ‰«æä»»åŠ¡")
        sys.exit(1)
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = SessionInheritanceAnalyzer()
    
    # æ‰§è¡Œåˆ†æ
    analysis = analyzer.analyze_session_inheritance(str(scan_result_file))
    
    # ä¿å­˜åˆ†ææŠ¥å‘Š
    analysis_file = output_dir / "session_inheritance_analysis.json"
    with open(analysis_file, 'w', encoding='utf-8') as f:
        json.dump(analysis, f, ensure_ascii=False, indent=2)
    
    # æ‰“å°æ‘˜è¦
    summary = analysis["summary"]
    file_patterns = analysis["file_creation_patterns"]
    timing = analysis["session_timing_analysis"]
    storage = analysis["storage_behavior_analysis"]
    
    print(f"\\nğŸ“Š Session IDç»§æ‰¿æœºåˆ¶åˆ†ææ‘˜è¦")
    print(f"ğŸ“ åŸºæœ¬ç»Ÿè®¡:")
    print(f"   æ€»Sessionæ•°: {summary['total_sessions']}")
    print(f"   æœ‰è®°å½•çš„Sessionæ•°: {summary['sessions_with_records']}")
    print(f"   æ€»è®°å½•æ•°: {summary['total_records']}")
    
    print(f"\\nğŸ—‚ï¸ æ–‡ä»¶åˆ›å»ºæ¨¡å¼:")
    print(f"   å³æ—¶åˆ›å»º: {file_patterns['immediate_creation']}ä¸ª (å¯èƒ½æ–°session)")
    print(f"   å»¶è¿Ÿåˆ›å»º: {file_patterns['delayed_creation']}ä¸ª (å¯èƒ½ç»§ç»­å†™å…¥)")
    print(f"   é¢„åˆ›å»º: {file_patterns['pre_creation']}ä¸ª (å¯èƒ½å¤ç”¨æ–‡ä»¶)")
    
    print(f"\\nâ° æ—¶é—´æ¨¡å¼:")
    print(f"   å¿«é€Ÿè¿ç»­session: {len(timing['rapid_succession_sessions'])}å¯¹")
    duration_dist = timing['session_duration_distribution']
    print(f"   æŒç»­æ—¶é—´åˆ†å¸ƒ: <6min: {duration_dist.get('<6min', 0)}, <1h: {duration_dist.get('<1hour', 0)}, 1-6h: {duration_dist.get('1-6hours', 0)}, >6h: {duration_dist.get('>6hours', 0)}")
    
    print(f"\\nğŸ’¾ å­˜å‚¨è¡Œä¸º:")
    print(f"   æ–°æ–‡ä»¶åˆ›å»º: {storage['new_file_creation']}ä¸ª")
    print(f"   æ–‡ä»¶ç»§ç»­å†™å…¥: {storage['file_continuation']}ä¸ª")
    
    print(f"\\nğŸ‰ T04ä»»åŠ¡å®Œæˆ! è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {analysis_file}")


if __name__ == "__main__":
    main()